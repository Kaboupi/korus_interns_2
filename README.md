# КОРУС Консалтинг. Задания для разработчика 2, 3
> Стажёр-разработчик Георгий Новожилов, команда 2

## 1. Описание
Задания: 
1. Написание DAG-ов для обработки таблиц из двух баз данных.
2. Разработка python-скрипта для загрузки, маппинга и фильтрации данных из источника в `dds`, согласно постановке от аналитика

- В процессе загрузки исправить все ошибки в данных, обнаруженные аналитиком
- Загрузку выполнять полной перезаписью данных в слое `dds`
- Обработку данных можно выполнять при помощи специализированной библиотеки (например, `pandas`), SQL-скриптов, либо обрабатывать чистым питоном
- Желательно минимизировать время недоступности слоя `dds` (время с момента удаления старых данных и до окончания записи новых). 
- Разработать `DAG` для запуска скрипта загрузки:  
- Отдельный скрипт, который считывает конфигурации и параметры подключения к БД и описывает задачу для запуска скрипта загрузки с нужными параметрами.  

ER-диаграмма БД **internship_2_db**:
![pic](https://github.com/Kaboupi/korus_interns_2/assets/24700915/99f8aa12-6e3a-4f9c-87a9-ef8aa5079b20)
(Тип данных transaction.pos - VARCHAR(150))

## 2. Структура
[**./crud/etl_functions.py**](crud/etl_functions.py) - Функции для обработки данных из таблиц, используемые в DAG \
[**./dags/dag_ddl_layers.py**](dags/dag_ddl_layers.py) - DAG, создающий схемы и сущности в БД команды \
[**./dags/dag_operate.py**](dags/dag_operate.py) - DAG, отвечающий за ETL процесс задания \
[**./dags/dag_select.py**](dags/dag_select.py) - DAG, выполняющий SELECT. Сохраняет полученные датафреймы в `./output`

В DAG-e **dag_operate.py** присутствуют комментарии к каждой операции. Ниже представлена структура и приложены скриншоты успешного выполнения DAG-ов:
```
├── crud
│   ├── __init__.py
│   ├── etl_functions.py
├── dags
│   ├── __init__.py
│   ├── dag_ddl_layers.py
│   ├── dag_operate.py
│   ├── dag_select.py
├── output
│   ├── data.csv
│   ├── data.json
├── output
│   ├── stores.csv
│   ├── transaction.csv
└── requirements.txt
```
Выполнение `dag_ddl_layers.py`:
![Выполнение `dag_ddl_layers.py`](https://github.com/Kaboupi/korus_interns_2/assets/24700915/722979ee-791b-447f-ba76-25d72afeda45)
Выполнение `dag_operate.py`
![Выполнение `dag_operate.py`](https://github.com/Kaboupi/korus_interns_2/assets/24700915/8a9b7477-1ba5-4172-98b2-1c839d75e90b)

## 3. Запуск
Запуск сервиса Apache Airflow происходил из нативно установленной версии. 
Инструкция к нативной установке указана в [официальной документации Apache Airflow](https://airflow.apache.org/docs/apache-airflow/stable/start.html)
Требуемые зависимости для корректной работы сервиса указаны в файле [requirements.txt](requirements.txt).

Настройка окружения (если модуль apache-airflow установлен в одно из виртуальных окружений, то предварительно активируйте его)
```bash
pip install -Ur requirements.txt
```
Для корректкой работы сервиса Apache Airflow не обязательно переходить в директорию с папкой, т.к. в проекте добавлены абсолютные пути в `sys.path`.
```bash
airflow standalone
```
